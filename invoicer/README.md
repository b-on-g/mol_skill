# Invoicer - Docker Installation

Локальная установка приложения "Заполнение документов по реквизитам" с использованием Docker Compose.

## Требования

- Docker
- Docker Compose
- Минимум 8 GB RAM (для работы LLM)
- 10 GB свободного места на диске

## Установка

### 1. Сборка приложения

Перед запуском Docker необходимо собрать статику приложения:

```bash
cd /path/to/mam
npm exec mam bog/mol/invoicer
```

### 2. Запуск

```bash
cd bog/mol/invoicer
docker compose up -d
```

При первом запуске:
- Скачивается образ Ollama
- Автоматически загружается модель qwen2.5:7b (~4.5 GB)
- Собирается образ nginx со статикой

### 3. Доступ

Откройте в браузере: http://localhost:8080

## Настройка LLM

Приложение автоматически использует локальную Ollama после настройки:

1. Откройте приложение
2. Нажмите шестерёнку (настройки) в правом верхнем углу
3. Введите:
   - **API URL:** `http://localhost:11434/v1`
   - **API Key:** оставьте пустым (для Ollama не нужен)
4. Нажмите "Распознать" — запросы пойдут на локальную модель

## Работа без интернета

После первого запуска (когда модель скачана) приложение работает полностью офлайн:

- Статика обслуживается локальным nginx
- LLM работает через локальную Ollama
- Никаких внешних запросов не выполняется

## Управление

```bash
# Запуск
docker compose up -d

# Остановка
docker compose down

# Просмотр логов
docker compose logs -f

# Просмотр логов Ollama
docker compose logs -f llm

# Перезапуск
docker compose restart
```

## Структура сервисов

| Сервис | Порт | Описание |
|--------|------|----------|
| web | 8080 | Nginx + статика приложения |
| llm | 11434 | Ollama с моделью qwen2.5:7b |

## Смена модели

Для использования другой модели:

```bash
# Подключиться к контейнеру Ollama
docker compose exec llm ollama pull llama3.2

# Или любую другую модель
docker compose exec llm ollama pull mistral
```

После этого в настройках приложения укажите `model` параметр (опционально).

## Troubleshooting

### Модель не загружается

```bash
# Проверить статус Ollama
docker compose logs llm

# Загрузить модель вручную
docker compose exec llm ollama pull qwen2.5:7b
```

### Приложение не открывается

```bash
# Проверить статус контейнеров
docker compose ps

# Проверить, что порт 8080 свободен
lsof -i :8080
```

### Не хватает памяти

Модель qwen2.5:7b требует около 5-6 GB RAM. Если памяти не хватает:

```bash
# Использовать меньшую модель
docker compose exec llm ollama pull qwen2.5:3b
```
